ğŸ¤ PrÃ©sentation : Architecture d'un Chatbot IA avec MCP, n8n et Next.js
DurÃ©e : 5 minutes

ğŸ“Œ Slide 1 : Introduction (30 secondes)
Projet : Chat-Help
Un assistant IA intelligent pour le support technique
Objectif :
CrÃ©er un chatbot capable de :

RÃ©pondre aux questions techniques
Naviguer sur le web en temps rÃ©el
MÃ©moriser les conversations
Utiliser des outils externes (MCP)

Technologies :

MCP (Model Context Protocol) : Protocole d'outils pour LLM
n8n : Orchestrateur de workflows
Ollama : LLM local (Llama2)
Next.js : Interface utilisateur


ğŸ—ï¸ Slide 2 : Architecture globale (1 minute)
Les 3 couches principales
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE 1 : Interface Utilisateur  â”‚
â”‚  Next.js (localhost:3000)           â”‚
â”‚  - Page chatbot                     â”‚
â”‚  - API Route                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP POST
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE 2 : Orchestration          â”‚
â”‚  n8n Workflow (Docker)              â”‚
â”‚  - Webhook                          â”‚
â”‚  - AI Agent                         â”‚
â”‚  - Formatage                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
         â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“     â†“     â†“         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE 3 : Services IA            â”‚
â”‚  - Ollama (LLM)                    â”‚
â”‚  - Postgres (MÃ©moire)              â”‚
â”‚  - MCP Server (Outils)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Point clÃ© :** SÃ©paration des responsabilitÃ©s

---

## ğŸ”Œ Slide 3 : MCP - Model Context Protocol (1 minute)

### Qu'est-ce que MCP ?

**ProblÃ¨me :** Les LLM sont limitÃ©s Ã  gÃ©nÃ©rer du texte
**Solution :** MCP leur donne accÃ¨s Ã  des outils externes

### Architecture MCP
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM        â”‚ "Je veux chercher sur le web"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Appelle l'outil
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Server  â”‚ Protocole JSON-RPC 2.0
â”‚              â”‚
â”‚  8 Outils :  â”‚
â”‚  âœ“ Navigation web
â”‚  âœ“ Veille techno
â”‚  âœ“ Analyse code
â”‚  âœ“ Blagues...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Communication : JSON-RPC 2.0
json// n8n â†’ MCP
{
  "method": "tools/call",
  "params": {
    "name": "navigate_web",
    "arguments": { "query": "actualitÃ©s IA" }
  }
}

// MCP â†’ n8n
{
  "result": {
    "content": "Voici les derniÃ¨res actualitÃ©s..."
  }
}
```

**Avantage :** Les LLM deviennent **actionnables**

---

## âš™ï¸ Slide 4 : n8n - L'orchestrateur (1 minute)

### Pourquoi n8n ?

**RÃ´le :** Coordonner tous les composants sans coder

### Workflow en 4 Ã©tapes
```
1. WEBHOOK
   â†“ ReÃ§oit : { message, userId, sessionId }
   
2. EXTRACT DATA
   â†“ PrÃ©pare les donnÃ©es
   
3. AI AGENT (le cerveau)
   â”‚
   â”œâ”€â–º Ollama : GÃ©nÃ¨re le texte
   â”œâ”€â–º Postgres Memory : Se souvient
   â””â”€â–º MCP Client : Utilise les outils
   â†“
   
4. FORMAT RESPONSE
   â†“ Retourne : { output, timestamp }
Configuration AI Agent
yamlChat Model: Ollama (llama2)
Memory: Postgres (historique)
Tools: MCP Client (8 outils)
```

**Point clÃ© :** **Tout est visual** dans n8n, pas besoin de coder

---

## ğŸŒ‰ Slide 5 : Communication Docker â†” Next.js (1 minute)

### Le dÃ©fi : Deux environnements sÃ©parÃ©s
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js (Machine HÃ´te)  â”‚
â”‚  localhost:3000          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Comment communiquer ?
         â”‚
         â†“ Port exposÃ© : 5678
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Network          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  n8n               â”‚  â”‚
â”‚  â”‚  port 5678:5678    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â†“         â†“       â†“   â”‚
â”‚  Ollama   MCP   Postgres â”‚
â”‚  :11434   :8080  :5432   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Solution : Ports exposÃ©s
Dans Docker :

RÃ©seau interne : http://chat-help-mcp:8080
Communication via hostnames

Depuis Next.js :

AccÃ¨s externe : http://localhost:5678
Via port exposÃ©

Code Next.js :
javascriptfetch('http://localhost:5678/webhook/chatbot', {
  method: 'POST',
  body: JSON.stringify({ message: "Bonjour" })
})
```

---

## ğŸ”„ Slide 6 : Flux complet (1 minute)

### De la question Ã  la rÃ©ponse
```
1. USER
   "Comment dÃ©ployer sur staging ?"
   â”‚
   â†“
2. NEXT.JS (API Route)
   POST /api/chatbot
   â”‚
   â†“ localhost:5678
3. N8N WEBHOOK
   ReÃ§oit la requÃªte
   â”‚
   â†“
4. AI AGENT dÃ©cide
   "Je dois chercher dans la documentation"
   â”‚
   â†“
5. MCP CLIENT
   Appelle navigate_web("staging deployment")
   â”‚
   â†“
6. MCP SERVER
   ExÃ©cute la recherche web
   â”‚
   â†“ Retourne les rÃ©sultats
7. OLLAMA
   GÃ©nÃ¨re une rÃ©ponse avec le contexte
   â”‚
   â†“
8. POSTGRES MEMORY
   Sauvegarde la conversation
   â”‚
   â†“
9. FORMAT RESPONSE
   Structure la rÃ©ponse
   â”‚
   â†“
10. RETOUR â†’ USER
    "Voici comment dÃ©ployer sur staging..."
```

**Temps total : ~3-5 secondes**

---

## ğŸ¯ Slide 7 : Concepts clÃ©s (30 secondes)

### Les 5 piliers du projet

| Concept | Technologie | RÃ´le |
|---------|-------------|------|
| **Protocole MCP** | JSON-RPC 2.0 | Communication standardisÃ©e LLM â†” Outils |
| **Orchestration** | n8n Workflow | Coordonne tous les services |
| **LLM Local** | Ollama (Llama2) | GÃ©nÃ¨re les rÃ©ponses |
| **MÃ©moire** | Postgres | Historique des conversations |
| **Conteneurisation** | Docker | Isolation et dÃ©ploiement |

### Avantages

âœ… **ModularitÃ©** : Chaque service est indÃ©pendant
âœ… **ExtensibilitÃ©** : Facile d'ajouter des outils MCP
âœ… **Privacy** : LLM local, donnÃ©es privÃ©es
âœ… **No-code** : n8n permet de modifier sans programmer

---

## ğŸš€ Slide 8 : DÃ©mo & Conclusion (30 secondes)

### Points forts

1. **Architecture moderne** : Microservices + Orchestration
2. **MCP** : Standard Ã©mergent pour les outils LLM
3. **Hybride** : Docker (backend) + Next.js (frontend)
4. **Scalable** : Facile d'ajouter Ollama, Qdrant, etc.

### Cas d'usage

- Support technique automatisÃ©
- Assistant de documentation
- Recherche intelligente
- Automatisation de tÃ¢ches

### Ã‰volutions possibles

- Ajouter d'autres modÃ¨les (GPT-4, Claude)
- Plus d'outils MCP (GitHub, Jira, Slack)
- Interface vocale
- Multi-utilisateurs avec authentification

---

## ğŸ“Š Slide Bonus : SchÃ©ma rÃ©capitulatif
```
           USER
            â”‚
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Next.js     â”‚
    â”‚  (Frontend)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ localhost:5678
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  n8n Workflow â”‚ â—„â”€â”€â”€ Orchestrateur
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“       â†“       â†“         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ Ollama â”‚ â”‚MCP â”‚ â”‚Memoryâ”‚ â”‚...   â”‚
â”‚  LLM   â”‚ â”‚8   â”‚ â”‚Post- â”‚ â”‚autresâ”‚
â”‚        â”‚ â”‚outilsâ”‚ â”‚gres â”‚ â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜

    Tout dans Docker

ğŸ¤ Script de prÃ©sentation (5 minutes)
[0:00-0:30] Introduction
"Bonjour, je vais vous prÃ©senter Chat-Help, un assistant IA intelligent que j'ai dÃ©veloppÃ©. Ce projet combine 3 technologies clÃ©s : MCP pour les outils, n8n pour l'orchestration, et Ollama pour le LLM."
[0:30-1:30] Architecture
"L'architecture se compose de 3 couches : l'interface Next.js, l'orchestrateur n8n, et les services IA dans Docker. Chaque couche a une responsabilitÃ© prÃ©cise, ce qui rend le systÃ¨me modulaire et maintenable."
[1:30-2:30] MCP Protocol
"Le point innovant est l'utilisation de MCP - Model Context Protocol. C'est un protocole qui permet aux LLM d'utiliser des outils externes. Par exemple, le chatbot peut chercher sur le web, analyser du code, ou faire de la veille technologique. La communication se fait via JSON-RPC 2.0."
[2:30-3:30] n8n Orchestrateur
"n8n coordonne tout. Un workflow visuel en 4 Ã©tapes : rÃ©ception du message, prÃ©paration des donnÃ©es, AI Agent qui utilise Ollama + MCP + la mÃ©moire Postgres, puis formatage de la rÃ©ponse. Tout est configurable sans coder."
[3:30-4:30] Communication
"Le dÃ©fi Ã©tait de connecter Next.js qui tourne sur la machine hÃ´te, avec n8n dans Docker. Solution : les ports exposÃ©s. Next.js appelle localhost:5678, qui est le port de n8n exposÃ© depuis Docker. Ã€ l'intÃ©rieur du rÃ©seau Docker, les services communiquent via leurs hostnames."
[4:30-5:00] Conclusion
"En rÃ©sumÃ© : une architecture modulaire, le protocole MCP qui donne des super-pouvoirs aux LLM, et une orchestration no-code avec n8n. Le systÃ¨me est extensible, privÃ© avec un LLM local, et scalable. Merci de votre attention !"